# core/integrations/openai_client.py

import asyncio
from typing import List, Dict, Any, Optional
import tiktoken
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion

from config.settings.base import settings
from loguru import logger


class OpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.openai.api_key)
        self.model = settings.openai.model
        self.max_tokens = settings.openai.max_tokens
        self.temperature = settings.openai.temperature

        # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        try:
            self.encoding = tiktoken.encoding_for_model(self.model)
        except KeyError:
            self.encoding = tiktoken.get_encoding("cl100k_base")

    async def generate_response(
            self,
            messages: List[Dict[str, str]],
            temperature: Optional[float] = None,
            max_tokens: Optional[int] = None,
            timeout: int = 30
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens = self._count_tokens(messages)
            if total_tokens > 15000:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                messages = self._trim_messages(messages, max_tokens=12000)
                logger.warning(f"‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {total_tokens} ‚Üí {self._count_tokens(messages)} —Ç–æ–∫–µ–Ω–æ–≤")

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            request_params = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature or self.temperature,
                "max_tokens": max_tokens or self.max_tokens,
                "timeout": timeout
            }

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            start_time = asyncio.get_event_loop().time()

            response: ChatCompletion = await self.client.chat.completions.create(**request_params)

            processing_time = asyncio.get_event_loop().time() - start_time

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if response.choices and response.choices[0].message:
                content = response.choices[0].message.content

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                tokens_used = response.usage.total_tokens if response.usage else 0
                logger.info(
                    f"ü§ñ OpenAI –æ—Ç–≤–µ—Ç: {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤, "
                    f"{processing_time:.2f}—Å, –º–æ–¥–µ–ª—å: {self.model}"
                )

                return content

            logger.warning("‚ö†Ô∏è OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except asyncio.TimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç)