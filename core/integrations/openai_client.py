# core/integrations/openai_client.py

import asyncio
from typing import List, Dict, Any, Optional
import tiktoken
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion

from config.settings.base import settings
from loguru import logger


class OpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

    def __init__(self):
        self.client: Optional[AsyncOpenAI] = None
        self.model = settings.openai.model
        self.max_tokens = settings.openai.max_tokens
        self.temperature = settings.openai.temperature
        self.encoding = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å API –∫–ª—é—á
        self._initialize()


# core/integrations/openai_client.py

import asyncio
from typing import List, Dict, Any, Optional
import tiktoken
from openai import AsyncOpenAI

from config.settings.base import settings
from loguru import logger


class OpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

    def __init__(self):
        self.client: Optional[AsyncOpenAI] = None
        self.model = settings.openai.model
        self.max_tokens = settings.openai.max_tokens
        self.temperature = settings.openai.temperature
        self.encoding = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å API –∫–ª—é—á
        self._initialize()

    def _initialize(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            api_key = settings.openai.api_key

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ API –∫–ª—é—á –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
            if not api_key or api_key in ["", "sk-your-openai-api-key"]:
                logger.warning("‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                return

            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            self.client = AsyncOpenAI(api_key=api_key)

            # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
            try:
                self.encoding = tiktoken.encoding_for_model(self.model)
            except KeyError:
                self.encoding = tiktoken.get_encoding("cl100k_base")

            logger.info(f"‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {self.model})")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI –∫–ª–∏–µ–Ω—Ç–∞: {e}")
            self.client = None

    async def generate_response(
            self,
            messages: List[Dict[str, str]],
            temperature: Optional[float] = None,
            max_tokens: Optional[int] = None,
            timeout: int = 30
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""

        if not self.client:
            logger.error("‚ùå OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens = self._count_tokens(messages)
            if total_tokens > 15000:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                messages = self._trim_messages(messages, max_tokens=12000)
                logger.warning(f"‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {total_tokens} ‚Üí {self._count_tokens(messages)} —Ç–æ–∫–µ–Ω–æ–≤")

            start_time = asyncio.get_event_loop().time()

            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature or self.temperature,
                max_tokens=max_tokens or self.max_tokens
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if response.choices and response.choices[0].message:
                content = response.choices[0].message.content

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                tokens_used = response.usage.total_tokens if response.usage else 0
                logger.info(
                    f"ü§ñ OpenAI –æ—Ç–≤–µ—Ç: {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤, "
                    f"{processing_time:.2f}—Å, –º–æ–¥–µ–ª—å: {self.model}"
                )

                return content

            logger.warning("‚ö†Ô∏è OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None

    def _count_tokens(self, messages: List[Dict[str, str]]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""
        if not self.encoding:
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4

        try:
            total_tokens = 0
            for message in messages:
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è ChatGPT
                total_tokens += len(self.encoding.encode(message.get("content", "")))
                total_tokens += 4  # –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç ~4 —Ç–æ–∫–µ–Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

            total_tokens += 2  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            return total_tokens

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4

    def _trim_messages(self, messages: List[Dict[str, str]], max_tokens: int = 12000) -> List[Dict[str, str]]:
        """–û–±—Ä–µ–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        if not messages or not self.encoding:
            return messages

        # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        system_message = messages[0] if messages[0].get("role") == "system" else None
        conversation_messages = messages[1:] if system_message else messages

        trimmed_messages = []
        current_tokens = 0

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if system_message:
            system_tokens = len(self.encoding.encode(system_message.get("content", "")))
            if system_tokens < max_tokens:
                trimmed_messages.append(system_message)
                current_tokens += system_tokens

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ü–∞ (—Å–∞–º—ã–µ –Ω–æ–≤—ã–µ)
        for message in reversed(conversation_messages):
            message_tokens = len(self.encoding.encode(message.get("content", ""))) + 4

            if current_tokens + message_tokens > max_tokens:
                break

            trimmed_messages.insert(-1 if system_message else 0, message)
            current_tokens += message_tokens

        return trimmed_messages

    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è OpenAI API"""
        if not self.client:
            return False

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Test"}],
                max_tokens=10
            )

            return bool(response.choices)

        except Exception as e:
            logger.error(f"‚ùå Health check OpenAI –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
            return False

    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        if not self.client:
            return {
                "success": False,
                "error": "–ö–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                "model": self.model
            }

        try:
            start_time = asyncio.get_event_loop().time()

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=50
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            return {
                "success": True,
                "model": self.model,
                "processing_time": round(processing_time, 2),
                "tokens_used": response.usage.total_tokens if response.usage else 0,
                "response_length": len(response.choices[0].message.content) if response.choices else 0
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ
try:
    openai_client = OpenAIClient()
except Exception as e:
    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å OpenAI –∫–ª–∏–µ–Ω—Ç: {e}")


    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    class DummyOpenAIClient:
        async def generate_response(self, *args, **kwargs):
            return None

        async def health_check(self):
            return False

        async def test_connection(self):
            return {"success": False, "error": "Client not initialized"}


    openai_client = DummyOpenAIClient()


    async def generate_response(
            self,
            messages: List[Dict[str, str]],
            temperature: Optional[float] = None,
            max_tokens: Optional[int] = None,
            timeout: int = 30
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""

        if not self.client:
            logger.error("‚ùå OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens = self._count_tokens(messages)
            if total_tokens > 15000:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                messages = self._trim_messages(messages, max_tokens=12000)
                logger.warning(f"‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {total_tokens} ‚Üí {self._count_tokens(messages)} —Ç–æ–∫–µ–Ω–æ–≤")

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏
            start_time = asyncio.get_event_loop().time()

            response: ChatCompletion = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature or self.temperature,
                max_tokens=max_tokens or self.max_tokens
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if response.choices and response.choices[0].message:
                content = response.choices[0].message.content

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                tokens_used = response.usage.total_tokens if response.usage else 0
                logger.info(
                    f"ü§ñ OpenAI –æ—Ç–≤–µ—Ç: {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤, "
                    f"{processing_time:.2f}—Å, –º–æ–¥–µ–ª—å: {self.model}"
                )

                return content

            logger.warning("‚ö†Ô∏è OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except asyncio.TimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç OpenAI –∑–∞–ø—Ä–æ—Å–∞ ({timeout}—Å)")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None


    def _count_tokens(self, messages: List[Dict[str, str]]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""
        if not self.encoding:
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4

        try:
            total_tokens = 0
            for message in messages:
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è ChatGPT
                total_tokens += len(self.encoding.encode(message.get("content", "")))
                total_tokens += 4  # –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç ~4 —Ç–æ–∫–µ–Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

            total_tokens += 2  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            return total_tokens

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4


    def _trim_messages(self, messages: List[Dict[str, str]], max_tokens: int = 12000) -> List[Dict[str, str]]:
        """–û–±—Ä–µ–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        if not messages or not self.encoding:
            return messages

        # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        system_message = messages[0] if messages[0].get("role") == "system" else None
        conversation_messages = messages[1:] if system_message else messages

        trimmed_messages = []
        current_tokens = 0

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if system_message:
            system_tokens = len(self.encoding.encode(system_message.get("content", "")))
            if system_tokens < max_tokens:
                trimmed_messages.append(system_message)
                current_tokens += system_tokens

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ü–∞ (—Å–∞–º—ã–µ –Ω–æ–≤—ã–µ)
        for message in reversed(conversation_messages):
            message_tokens = len(self.encoding.encode(message.get("content", ""))) + 4

            if current_tokens + message_tokens > max_tokens:
                break

            trimmed_messages.insert(-1 if system_message else 0, message)
            current_tokens += message_tokens

        return trimmed_messages


    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è OpenAI API"""
        if not self.client:
            return False

        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Test"}],
                max_tokens=10
            )

            return bool(response.choices)

        except Exception as e:
            logger.error(f"‚ùå Health check OpenAI –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
            return False


    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        if not self.client:
            return {
                "success": False,
                "error": "–ö–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                "model": self.model
            }

        try:
            start_time = asyncio.get_event_loop().time()

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=50
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            return {
                "success": True,
                "model": self.model,
                "processing_time": round(processing_time, 2),
                "tokens_used": response.usage.total_tokens if response.usage else 0,
                "response_length": len(response.choices[0].message.content) if response.choices else 0
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ
try:
    openai_client = OpenAIClient()
except Exception as e:
    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å OpenAI –∫–ª–∏–µ–Ω—Ç: {e}")


    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    class DummyOpenAIClient:
        async def generate_response(self, *args, **kwargs):
            return None

        async def health_check(self):
            return False

        async def test_connection(self):
            return {"success": False, "error": "Client not initialized"}


    openai_client = DummyOpenAIClient()


    async def generate_response(
            self,
            messages: List[Dict[str, str]],
            temperature: Optional[float] = None,
            max_tokens: Optional[int] = None,
            timeout: int = 30
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""

        if not self.client:
            logger.error("‚ùå OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return None

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens = self._count_tokens(messages)
            if total_tokens > 15000:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                messages = self._trim_messages(messages, max_tokens=12000)
                logger.warning(f"‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {total_tokens} ‚Üí {self._count_tokens(messages)} —Ç–æ–∫–µ–Ω–æ–≤")

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            request_params = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature or self.temperature,
                "max_tokens": max_tokens or self.max_tokens,
                "timeout": timeout
            }

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            start_time = asyncio.get_event_loop().time()

            response: ChatCompletion = await self.client.chat.completions.create(**request_params)

            processing_time = asyncio.get_event_loop().time() - start_time

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if response.choices and response.choices[0].message:
                content = response.choices[0].message.content

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                tokens_used = response.usage.total_tokens if response.usage else 0
                logger.info(
                    f"ü§ñ OpenAI –æ—Ç–≤–µ—Ç: {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤, "
                    f"{processing_time:.2f}—Å, –º–æ–¥–µ–ª—å: {self.model}"
                )

                return content

            logger.warning("‚ö†Ô∏è OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except asyncio.TimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç OpenAI –∑–∞–ø—Ä–æ—Å–∞ ({timeout}—Å)")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None


    def _count_tokens(self, messages: List[Dict[str, str]]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""
        if not self.encoding:
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4

        try:
            total_tokens = 0
            for message in messages:
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è ChatGPT
                total_tokens += len(self.encoding.encode(message.get("content", "")))
                total_tokens += 4  # –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç ~4 —Ç–æ–∫–µ–Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

            total_tokens += 2  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            return total_tokens

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4


    def _trim_messages(self, messages: List[Dict[str, str]], max_tokens: int = 12000) -> List[Dict[str, str]]:
        """–û–±—Ä–µ–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        if not messages or not self.encoding:
            return messages

        # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        system_message = messages[0] if messages[0].get("role") == "system" else None
        conversation_messages = messages[1:] if system_message else messages

        trimmed_messages = []
        current_tokens = 0

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if system_message:
            system_tokens = len(self.encoding.encode(system_message.get("content", "")))
            if system_tokens < max_tokens:
                trimmed_messages.append(system_message)
                current_tokens += system_tokens

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ü–∞ (—Å–∞–º—ã–µ –Ω–æ–≤—ã–µ)
        for message in reversed(conversation_messages):
            message_tokens = len(self.encoding.encode(message.get("content", ""))) + 4

            if current_tokens + message_tokens > max_tokens:
                break

            trimmed_messages.insert(-1 if system_message else 0, message)
            current_tokens += message_tokens

        return trimmed_messages


    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è OpenAI API"""
        if not self.client:
            return False

        try:
            test_messages = [
                {"role": "user", "content": "Test"}
            ]

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=test_messages,
                max_tokens=10,
                timeout=10
            )

            return bool(response.choices)

        except Exception as e:
            logger.error(f"‚ùå Health check OpenAI –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
            return False


    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        if not self.client:
            return {
                "success": False,
                "error": "–ö–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                "model": self.model
            }

        try:
            start_time = asyncio.get_event_loop().time()

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=50,
                timeout=15
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            return {
                "success": True,
                "model": self.model,
                "processing_time": round(processing_time, 2),
                "tokens_used": response.usage.total_tokens if response.usage else 0,
                "response_length": len(response.choices[0].message.content) if response.choices else 0
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞ - —Å–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ
def create_openai_client():
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞"""
    try:
        return OpenAIClient()
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å OpenAI –∫–ª–∏–µ–Ω—Ç: {e}")

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        class DummyClient:
            async def generate_response(self, *args, **kwargs):
                return None

            async def health_check(self):
                return False

            async def test_connection(self):
                return {"success": False, "error": "Client not initialized"}

        return DummyClient()


openai_client = create_openai_client()