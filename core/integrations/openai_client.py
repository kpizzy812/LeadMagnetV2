# core/integrations/openai_client.py

import asyncio
from typing import List, Dict, Any, Optional
import tiktoken
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletion

from config.settings.base import settings
from loguru import logger


class OpenAIClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""

    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.openai.api_key)
        self.model = settings.openai.model
        self.max_tokens = settings.openai.max_tokens
        self.temperature = settings.openai.temperature

        # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        try:
            self.encoding = tiktoken.encoding_for_model(self.model)
        except KeyError:
            self.encoding = tiktoken.get_encoding("cl100k_base")

    async def generate_response(
            self,
            messages: List[Dict[str, str]],
            temperature: Optional[float] = None,
            max_tokens: Optional[int] = None,
            timeout: int = 30
    ) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI"""

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            total_tokens = self._count_tokens(messages)
            if total_tokens > 15000:  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Å—Ç–æ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
                messages = self._trim_messages(messages, max_tokens=12000)
                logger.warning(f"‚ö†Ô∏è –û–±—Ä–µ–∑–∞–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è: {total_tokens} ‚Üí {self._count_tokens(messages)} —Ç–æ–∫–µ–Ω–æ–≤")

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            request_params = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature or self.temperature,
                "max_tokens": max_tokens or self.max_tokens,
                "timeout": timeout
            }

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
            start_time = asyncio.get_event_loop().time()

            response: ChatCompletion = await self.client.chat.completions.create(**request_params)

            processing_time = asyncio.get_event_loop().time() - start_time

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            if response.choices and response.choices[0].message:
                content = response.choices[0].message.content

                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                tokens_used = response.usage.total_tokens if response.usage else 0
                logger.info(
                    f"ü§ñ OpenAI –æ—Ç–≤–µ—Ç: {tokens_used} —Ç–æ–∫–µ–Ω–æ–≤, "
                    f"{processing_time:.2f}—Å, –º–æ–¥–µ–ª—å: {self.model}"
                )

                return content

            logger.warning("‚ö†Ô∏è OpenAI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return None

        except asyncio.TimeoutError:
            logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç OpenAI –∑–∞–ø—Ä–æ—Å–∞ ({timeout}—Å)")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None

    def _count_tokens(self, messages: List[Dict[str, str]]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""
        try:
            total_tokens = 0
            for message in messages:
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è ChatGPT
                total_tokens += len(self.encoding.encode(message.get("content", "")))
                total_tokens += 4  # –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç ~4 —Ç–æ–∫–µ–Ω–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

            total_tokens += 2  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            return total_tokens

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: {e}")
            # –ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω
            return sum(len(msg.get("content", "")) for msg in messages) // 4

    def _trim_messages(self, messages: List[Dict[str, str]], max_tokens: int = 12000) -> List[Dict[str, str]]:
        """–û–±—Ä–µ–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        if not messages:
            return messages

        # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        system_message = messages[0] if messages[0].get("role") == "system" else None
        conversation_messages = messages[1:] if system_message else messages

        trimmed_messages = []
        current_tokens = 0

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if system_message:
            system_tokens = len(self.encoding.encode(system_message.get("content", "")))
            if system_tokens < max_tokens:
                trimmed_messages.append(system_message)
                current_tokens += system_tokens

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–æ–Ω—Ü–∞ (—Å–∞–º—ã–µ –Ω–æ–≤—ã–µ)
        for message in reversed(conversation_messages):
            message_tokens = len(self.encoding.encode(message.get("content", ""))) + 4

            if current_tokens + message_tokens > max_tokens:
                break

            trimmed_messages.insert(-1 if system_message else 0, message)
            current_tokens += message_tokens

        return trimmed_messages

    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è OpenAI API"""
        try:
            test_messages = [
                {"role": "user", "content": "Test"}
            ]

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=test_messages,
                max_tokens=10,
                timeout=10
            )

            return bool(response.choices)

        except Exception as e:
            logger.error(f"‚ùå Health check OpenAI –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
            return False

    async def test_connection(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        try:
            start_time = asyncio.get_event_loop().time()

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=50,
                timeout=15
            )

            processing_time = asyncio.get_event_loop().time() - start_time

            return {
                "success": True,
                "model": self.model,
                "processing_time": round(processing_time, 2),
                "tokens_used": response.usage.total_tokens if response.usage else 0,
                "response_length": len(response.choices[0].message.content) if response.choices else 0
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model": self.model
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
openai_client = OpenAIClient()